{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cf90ab2-42b9-4c0d-89f0-0469e54881ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mast\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpywt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msignal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m welch, spectrogram\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pywt\\__init__.py:23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dwt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_swt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_cwt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_mra\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pywt\\_cwt.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m     fftmodule \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mfft\n\u001b[0;32m     20\u001b[0m     next_fast_len \u001b[38;5;241m=\u001b[39m fftmodule\u001b[38;5;241m.\u001b[39mnext_fast_len\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\__init__.py:134\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name):\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m submodules:\n\u001b[1;32m--> 134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscipy.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\fft\\__init__.py:90\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_basic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     86\u001b[0m     fft, ifft, fft2, ifft2, fftn, ifftn,\n\u001b[0;32m     87\u001b[0m     rfft, irfft, rfft2, irfft2, rfftn, irfftn,\n\u001b[0;32m     88\u001b[0m     hfft, ihfft, hfft2, ihfft2, hfftn, ihfftn)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_realtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dct, idct, dst, idst, dctn, idctn, dstn, idstn\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fftlog\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fht, ifht, fhtoffset\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_helper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m next_fast_len, fftfreq, rfftfreq, fftshift, ifftshift\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_backend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (set_backend, skip_backend, set_global_backend,\n\u001b[0;32m     93\u001b[0m                        register_backend)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\fft\\_fftlog.py:10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_basic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _dispatch\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01muarray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dispatchable\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fftlog_backend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fhtoffset\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     13\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfht\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mifht\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfhtoffset\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\fft\\_fftlog_backend.py:4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m warn\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_basic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rfft, irfft\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m loggamma, poch\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array_namespace, copy\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfht\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mifht\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfhtoffset\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\special\\__init__.py:777\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sf_error\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SpecialFunctionWarning, SpecialFunctionError\n\u001b[1;32m--> 777\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _ufuncs\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ufuncs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;66;03m# Replace some function definitions from _ufuncs to add Array API support\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\special\\_ufuncs.pyx:1\u001b[0m, in \u001b[0;36minit scipy.special._ufuncs\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import pywt\n",
    "from scipy.signal import welch, spectrogram\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                             roc_auc_score, roc_curve, precision_recall_curve,\n",
    "                             average_precision_score)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# ----------------------------\n",
    "# Data Loading and Preparation\n",
    "# ----------------------------\n",
    "df = pd.read_csv('final_classification_dataset.csv')\n",
    "\n",
    "def safe_convert(signal):\n",
    "    try:\n",
    "        if isinstance(signal, str):\n",
    "            arr = np.array(ast.literal_eval(signal))\n",
    "        elif isinstance(signal, np.ndarray):\n",
    "            arr = signal\n",
    "        else:\n",
    "            arr = np.zeros(100)\n",
    "        if len(arr) < 100:\n",
    "            arr = np.pad(arr, (0, 100 - len(arr)), 'constant')\n",
    "        return arr[:100]\n",
    "    except:\n",
    "        return np.zeros(100)\n",
    "\n",
    "df['clean_signal'] = df['clean_signal'].apply(safe_convert)\n",
    "df['noise_signal'] = df['noise_signal'].apply(safe_convert)\n",
    "\n",
    "# ----------------------------\n",
    "# Feature Extraction Functions\n",
    "# ----------------------------\n",
    "def extract_enhanced_features(signal, fs=1000):\n",
    "    features = {\n",
    "        'mean': np.mean(signal),\n",
    "        'std': np.std(signal),\n",
    "        'max': np.max(signal),\n",
    "        'min': np.min(signal),\n",
    "        'median': np.median(signal),\n",
    "        'q25': np.percentile(signal, 25),\n",
    "        'q75': np.percentile(signal, 75),\n",
    "        'rms': np.sqrt(np.mean(signal**2)),\n",
    "        'zero_crossings': ((signal[:-1] * signal[1:]) < 0).sum(),\n",
    "        'entropy': np.sum(-signal * np.log(signal + 1e-10)),\n",
    "        'skewness': pd.Series(signal).skew(),\n",
    "        'kurtosis': pd.Series(signal).kurtosis()\n",
    "    }\n",
    "    try:\n",
    "        f, Pxx = welch(signal, fs=fs, nperseg=min(len(signal), 256))\n",
    "        features.update({\n",
    "            'spectral_centroid': np.sum(f * Pxx) / np.sum(Pxx),\n",
    "            'spectral_bandwidth': np.sqrt(np.sum((f - features['spectral_centroid'])**2 * Pxx)),\n",
    "            'spectral_entropy': -np.sum(Pxx * np.log2(Pxx + 1e-12)),\n",
    "            'spectral_flatness': np.exp(np.mean(np.log(Pxx + 1e-10))) / np.mean(Pxx),\n",
    "            'spectral_energy': np.sum(Pxx),\n",
    "            'peak_frequency': f[np.argmax(Pxx)]\n",
    "        })\n",
    "    except:\n",
    "        features.update({k: 0 for k in ['spectral_centroid', 'spectral_bandwidth', \n",
    "                                          'spectral_entropy', 'spectral_flatness',\n",
    "                                          'spectral_energy', 'peak_frequency']})\n",
    "    try:\n",
    "        coeffs = pywt.wavedec(signal, 'db1', level=3)\n",
    "        for i, c in enumerate(coeffs):\n",
    "            features.update({\n",
    "                f'wavelet_l{i}_mean': np.mean(c),\n",
    "                f'wavelet_l{i}_std': np.std(c),\n",
    "                f'wavelet_l{i}_energy': np.sum(c**2),\n",
    "                f'wavelet_l{i}_entropy': -np.sum(c**2 * np.log(c**2 + 1e-10))\n",
    "            })\n",
    "        total_energy = np.sum([np.sum(c**2) for c in coeffs])\n",
    "        features.update({\n",
    "            'wavelet_total_energy': total_energy,\n",
    "            'wavelet_energy_ratio': np.sum(coeffs[0]**2) / (total_energy + 1e-10)\n",
    "        })\n",
    "    except:\n",
    "        wavelet_features = {f'wavelet_l{i}_{j}': 0 for i in range(4) for j in ['mean', 'std', 'energy', 'entropy']}\n",
    "        wavelet_features.update({'wavelet_total_energy': 0, 'wavelet_energy_ratio': 0})\n",
    "        features.update(wavelet_features)\n",
    "    return features\n",
    "\n",
    "def extract_spectrogram_features(signal, fs=1000):\n",
    "    features = {}\n",
    "    try:\n",
    "        f, t, Sxx = spectrogram(signal, fs=fs, nperseg=256)\n",
    "        spectral_centroid = np.sum(f[:, None] * Sxx, axis=0) / np.sum(Sxx, axis=0)\n",
    "        features.update({\n",
    "            'spec_centroid_mean': np.mean(spectral_centroid),\n",
    "            'spec_centroid_std': np.std(spectral_centroid),\n",
    "            'spec_centroid_max': np.max(spectral_centroid),\n",
    "            'spec_centroid_min': np.min(spectral_centroid)\n",
    "        })\n",
    "        spectral_bandwidth = np.sqrt(np.sum((f[:, None] - spectral_centroid)**2 * Sxx, axis=0) / np.sum(Sxx, axis=0))\n",
    "        features.update({\n",
    "            'spec_bandwidth_mean': np.mean(spectral_bandwidth),\n",
    "            'spec_bandwidth_std': np.std(spectral_bandwidth)\n",
    "        })\n",
    "        spectral_entropy = -np.sum(Sxx * np.log(Sxx + 1e-10), axis=0)\n",
    "        features.update({\n",
    "            'spec_entropy_mean': np.mean(spectral_entropy),\n",
    "            'spec_entropy_std': np.std(spectral_entropy)\n",
    "        })\n",
    "        spectral_flatness = np.exp(np.mean(np.log(Sxx + 1e-10), axis=0)) / np.mean(Sxx, axis=0)\n",
    "        features.update({\n",
    "            'spec_flatness_mean': np.mean(spectral_flatness),\n",
    "            'spec_flatness_std': np.std(spectral_flatness)\n",
    "        })\n",
    "        spectral_energy = np.sum(Sxx, axis=0)\n",
    "        features.update({\n",
    "            'spec_energy_mean': np.mean(spectral_energy),\n",
    "            'spec_energy_std': np.std(spectral_energy),\n",
    "            'spec_total_energy': np.sum(Sxx),\n",
    "            'spec_peak_freq': f[np.argmax(np.mean(Sxx, axis=1))]\n",
    "        })\n",
    "    except:\n",
    "        spec_features = {\n",
    "            'spec_centroid_mean': 0, 'spec_centroid_std': 0,\n",
    "            'spec_centroid_max': 0, 'spec_centroid_min': 0,\n",
    "            'spec_bandwidth_mean': 0, 'spec_bandwidth_std': 0,\n",
    "            'spec_entropy_mean': 0, 'spec_entropy_std': 0,\n",
    "            'spec_flatness_mean': 0, 'spec_flatness_std': 0,\n",
    "            'spec_energy_mean': 0, 'spec_energy_std': 0,\n",
    "            'spec_total_energy': 0, 'spec_peak_freq': 0\n",
    "        }\n",
    "        features.update(spec_features)\n",
    "    return features\n",
    "\n",
    "def extract_all_features(signal, fs=1000):\n",
    "    if isinstance(signal, str):\n",
    "        try:\n",
    "            signal = np.array(ast.literal_eval(signal))\n",
    "        except:\n",
    "            signal = np.zeros(100)\n",
    "    features = {}\n",
    "    features.update(extract_enhanced_features(signal, fs))\n",
    "    features.update(extract_spectrogram_features(signal, fs))\n",
    "    return features\n",
    "\n",
    "# ----------------------------\n",
    "# Extração dos Features\n",
    "# ----------------------------\n",
    "print(\"Extraindo features dos sinais...\")\n",
    "clean_features = pd.DataFrame(df['clean_signal'].apply(lambda x: extract_all_features(x, fs=1000)).tolist()).add_prefix('clean_')\n",
    "noise_features = pd.DataFrame(df['noise_signal'].apply(lambda x: extract_all_features(x, fs=1000)).tolist()).add_prefix('noise_')\n",
    "X = pd.concat([clean_features, noise_features, df[['clean_signal_strength', 'noise_signal_strength']]], axis=1)\n",
    "y = df['class']\n",
    "X = X.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "# ----------------------------\n",
    "# Divisão em Treino e Teste\n",
    "# ----------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# ----------------------------\n",
    "# Balanceamento e Escalonamento\n",
    "# ----------------------------\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ----------------------------\n",
    "# Construção e Treinamento do Modelo MLP\n",
    "# ----------------------------\n",
    "print(\"Construindo a rede neural MLP...\")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Exemplo: ajuste de class_weight (opcional, se desejar penalizar mais a classe positiva)\n",
    "# Como os dados já foram balanceados pelo SMOTE, esse parâmetro pode ser testado para melhorar a sensibilidade.\n",
    "class_weight = {0: 1.0, 1: 1.5}\n",
    "\n",
    "print(\"Treinando a rede neural...\")\n",
    "history = model.fit(X_train_scaled, y_train_res, epochs=100, batch_size=32, validation_split=0.3,\n",
    "                    callbacks=[early_stop], verbose=2, class_weight=class_weight)\n",
    "\n",
    "# ----------------------------\n",
    "# Avaliação do Modelo MLP\n",
    "# ----------------------------\n",
    "print(\"Avaliando o modelo MLP...\")\n",
    "y_pred_prob = model.predict(X_test_scaled)\n",
    "# Ajuste do threshold: experimente valores abaixo de 0.5 para melhorar o recall da classe positiva\n",
    "threshold = 0.45\n",
    "y_pred = (y_pred_prob > threshold).astype(int)\n",
    "\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Не сигнал', 'Сигнал присутствует']))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Не сигнал', 'Сигнал присутствует'],\n",
    "            yticklabels=['Не сигнал', 'Сигнал присутствует'])\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.ylabel('Classe Verdadeira')\n",
    "plt.xlabel('Classe Predita')\n",
    "plt.show()\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr, tpr, label=f'ROC (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('Taxa de Falsos Positivos')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "ap_score = average_precision_score(y_test, y_pred_prob)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, label=f'PR (AP = {ap_score:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Curva Precision-Recall')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cea2c17-9ef9-499b-be88-fb9704b5eb79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1612e609-d24b-41ee-8939-9dd0ee1e5312",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
